{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FashionMNIST2D(MNIST):\n",
    "    '''Implement Dataset with FashionMnist'''\n",
    "    urls = [\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz',\n",
    "        'http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz',\n",
    "    ]\n",
    "\n",
    "class FashionModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(FashionModel, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "FASHION_DIR = '/home/erikreppel/data/fashion-mnist/'\n",
    "MNIST_DIR = '/home/erikreppel/data/mnist/'\n",
    "\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.1307,), (0.3081,))])\n",
    "\n",
    "trainset = FashionMNIST2D(FASHION_DIR, download=True,\n",
    "            transform=transform)\n",
    "testset = FashionMNIST2D(FASHION_DIR, train=False, download=True,\n",
    "                                    transform=transform)\n",
    "\n",
    "batch_size = 256\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=trainset,\n",
    "                                           batch_size=batch_size,\n",
    "                                           shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=testset,\n",
    "                                          batch_size=batch_size,\n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment import Experiment\n",
    "\n",
    "model = FashionModel()\n",
    "\n",
    "exp = Experiment(model, viz_logging=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters())\n",
    "\n",
    "exp.compile(optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN epoch: 0 avg_loss: 0.004187234059969584\n",
      "VALIDATION: Epoch: 0 \n",
      "Avg loss: 0.0024, Accuracy: 0.7623\n",
      "VALIDATION: Epoch: 1 \n",
      "Avg loss: 0.0021, Accuracy: 0.7933\n",
      "TRAIN epoch: 2 avg_loss: 0.002485749518374602\n",
      "VALIDATION: Epoch: 2 \n",
      "Avg loss: 0.0020, Accuracy: 0.8074\n",
      "VALIDATION: Epoch: 3 \n",
      "Avg loss: 0.0018, Accuracy: 0.8188\n",
      "TRAIN epoch: 4 avg_loss: 0.0022139920214811963\n",
      "VALIDATION: Epoch: 4 \n",
      "Avg loss: 0.0018, Accuracy: 0.8318\n",
      "VALIDATION: Epoch: 5 \n",
      "Avg loss: 0.0017, Accuracy: 0.8404\n",
      "TRAIN epoch: 6 avg_loss: 0.00205288261671861\n",
      "VALIDATION: Epoch: 6 \n",
      "Avg loss: 0.0016, Accuracy: 0.8515\n",
      "VALIDATION: Epoch: 7 \n",
      "Avg loss: 0.0016, Accuracy: 0.8543\n",
      "TRAIN epoch: 8 avg_loss: 0.0019563588003317514\n",
      "VALIDATION: Epoch: 8 \n",
      "Avg loss: 0.0015, Accuracy: 0.8619\n",
      "VALIDATION: Epoch: 9 \n",
      "Avg loss: 0.0015, Accuracy: 0.8659\n"
     ]
    }
   ],
   "source": [
    "exp.fit(train_loader, n_epoch=10, valid_loader=test_loader, valid_freq=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEST: Avg loss: 0.0015, Accuracy: 0.8659\n"
     ]
    }
   ],
   "source": [
    "exp.evaluate(test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
